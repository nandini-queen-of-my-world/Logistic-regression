{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqB21QOgMg-G"
   },
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rALI06-oHusw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyKe9o2ONeFv"
   },
   "source": [
    "Data Collection & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CpStHH8KNcYB"
   },
   "outputs": [],
   "source": [
    "# loading the data from csv file to a pandas Dataframe\n",
    "raw_mail_data = pd.read_csv('mail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdn-7VE2NxsZ",
    "outputId": "28c19d96-23a2-43c0-86ad-5c1aee7f1b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_mail_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yhakjIE1N011"
   },
   "outputs": [],
   "source": [
    "# replace the null values with a null string\n",
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "SJey6H-SOWeK",
    "outputId": "af1b0dfd-2ff9-4af9-cfcd-d0c177dd6ab9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the first 5 rows of the dataframe\n",
    "mail_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbK82N2gOdar",
    "outputId": "4d1840a1-22b5-468f-d4d0-a4528ef4313c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of rows and columns in the dataframe\n",
    "mail_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhR4U3ATPBdk"
   },
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9EW7QSgeOt4p"
   },
   "outputs": [],
   "source": [
    "# label spam mail as 0;  ham mail as 1;\n",
    "\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxZK1fWwPwII"
   },
   "source": [
    "spam  -  0\n",
    "\n",
    "ham  -  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t8Rt-FaNPtPE"
   },
   "outputs": [],
   "source": [
    "# separating the data as texts and label\n",
    "\n",
    "X = mail_data['Message']\n",
    "\n",
    "Y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnQeUBGtQPP7",
    "outputId": "a2640f4b-2a1d-4742-9742-3ecbb6017668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                 Will ü b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: Message, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuWDNy5KQQjY",
    "outputId": "1a0a109b-d63a-4cf0-fe4e-b486f1d3d623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       0\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "5567    0\n",
      "5568    1\n",
      "5569    1\n",
      "5570    1\n",
      "5571    1\n",
      "Name: Category, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvHyqdH8QZPH"
   },
   "source": [
    "Splitting the data into training data & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RO2GmbSNQSQH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS2c7A4NRa46",
    "outputId": "5d44247f-65d0-457d-8a94-0fd8b45a3b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYQpiACGSBYM"
   },
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nLs847nSRibm"
   },
   "outputs": [],
   "source": [
    "# transform the text data to feature vectors that can be used as input to the Logistic regression\n",
    "\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "# convert Y_train and Y_test values as integers\n",
    "\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dBMAcw9RUkUY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075                  Don know. I did't msg him recently.\n",
      "1787    Do you know why god created gap between your f...\n",
      "1614                         Thnx dude. u guys out 2nite?\n",
      "4304                                      Yup i'm free...\n",
      "3266    44 7732584351, Do you want a New Nokia 3510i c...\n",
      "                              ...                        \n",
      "789     5 Free Top Polyphonic Tones call 087018728737,...\n",
      "968     What do u want when i come back?.a beautiful n...\n",
      "1667    Guess who spent all last night phasing in and ...\n",
      "3321    Eh sorry leh... I din c ur msg. Not sad alread...\n",
      "1688    Free Top ringtone -sub to weekly ringtone-get ...\n",
      "Name: Message, Length: 4457, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1NFuGogZUpt0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5413)\t0.6198254967574347\n",
      "  (0, 4456)\t0.4168658090846482\n",
      "  (0, 2224)\t0.413103377943378\n",
      "  (0, 3811)\t0.34780165336891333\n",
      "  (0, 2329)\t0.38783870336935383\n",
      "  (1, 4080)\t0.18880584110891163\n",
      "  (1, 3185)\t0.29694482957694585\n",
      "  (1, 3325)\t0.31610586766078863\n",
      "  (1, 2957)\t0.3398297002864083\n",
      "  (1, 2746)\t0.3398297002864083\n",
      "  (1, 918)\t0.22871581159877646\n",
      "  (1, 1839)\t0.2784903590561455\n",
      "  (1, 2758)\t0.3226407885943799\n",
      "  (1, 2956)\t0.33036995955537024\n",
      "  (1, 1991)\t0.33036995955537024\n",
      "  (1, 3046)\t0.2503712792613518\n",
      "  (1, 3811)\t0.17419952275504033\n",
      "  (2, 407)\t0.509272536051008\n",
      "  (2, 3156)\t0.4107239318312698\n",
      "  (2, 2404)\t0.45287711070606745\n",
      "  (2, 6601)\t0.6056811524587518\n",
      "  (3, 2870)\t0.5864269879324768\n",
      "  (3, 7414)\t0.8100020912469564\n",
      "  (4, 50)\t0.23633754072626942\n",
      "  (4, 5497)\t0.15743785051118356\n",
      "  :\t:\n",
      "  (4454, 4602)\t0.2669765732445391\n",
      "  (4454, 3142)\t0.32014451677763156\n",
      "  (4455, 2247)\t0.37052851863170466\n",
      "  (4455, 2469)\t0.35441545511837946\n",
      "  (4455, 5646)\t0.33545678464631296\n",
      "  (4455, 6810)\t0.29731757715898277\n",
      "  (4455, 6091)\t0.23103841516927642\n",
      "  (4455, 7113)\t0.30536590342067704\n",
      "  (4455, 3872)\t0.3108911491788658\n",
      "  (4455, 4715)\t0.30714144758811196\n",
      "  (4455, 6916)\t0.19636985317119715\n",
      "  (4455, 3922)\t0.31287563163368587\n",
      "  (4455, 4456)\t0.24920025316220423\n",
      "  (4456, 141)\t0.292943737785358\n",
      "  (4456, 647)\t0.30133182431707617\n",
      "  (4456, 6311)\t0.30133182431707617\n",
      "  (4456, 5569)\t0.4619395404299172\n",
      "  (4456, 6028)\t0.21034888000987115\n",
      "  (4456, 7154)\t0.24083218452280053\n",
      "  (4456, 7150)\t0.3677554681447669\n",
      "  (4456, 6249)\t0.17573831794959716\n",
      "  (4456, 6307)\t0.2752760476857975\n",
      "  (4456, 334)\t0.2220077711654938\n",
      "  (4456, 5778)\t0.16243064490100795\n",
      "  (4456, 2870)\t0.31523196273113385\n"
     ]
    }
   ],
   "source": [
    "print(X_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q86FvELbU_SV"
   },
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hV6BAIZQVBbo"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1JeAOwzpUv0V"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWGRHWAPVI_z",
    "outputId": "1c5e15dd-0e07-4871-c4fa-b908ee400b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the Logistic Regression model with the training data\n",
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ01fa8dVeL5"
   },
   "source": [
    "Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ExiF2kKxVYtC"
   },
   "outputs": [],
   "source": [
    "# prediction on training data\n",
    "\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7t4DI5UWCkB",
    "outputId": "49fafbb0-0e7f-40c7-9ab7-4aea165731ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data :  0.9670181736594121\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data : ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cTin5rXTWKg3"
   },
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gvoMK4OWnJY",
    "outputId": "7bf56da4-1987-4828-ea00-95c30fb083d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data :  0.9659192825112107\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test data : ', accuracy_on_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXdOKxYAXaHC"
   },
   "source": [
    "Building a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60z1__mWql6",
    "outputId": "3aac53f3-13f2-4afb-e9f2-75d337cbcd44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times\"]\n",
    "\n",
    "# convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Cost: 0.6931471805599451\n",
      "Iteration 1000, Cost: 0.3601088071105369\n",
      "Iteration 2000, Cost: 0.3319812067610665\n",
      "Iteration 3000, Cost: 0.3071811332168107\n",
      "Iteration 4000, Cost: 0.28549694412307874\n",
      "Accuracy on training data: 0.8721112856181288\n",
      "Accuracy on test data: 0.8690582959641255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to sigmoid activation\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Function to calculate cost and gradient\n",
    "def compute_cost_and_gradient(X, y, theta, lambda_val=0):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    regularization_term = (lambda_val / (2 * m)) * np.sum(np.square(theta[1:]))\n",
    "    \n",
    "    cost = (-1 / m) * (np.dot(y, np.log(h)) + np.dot((1 - y), np.log(1 - h))) + regularization_term\n",
    "    \n",
    "    # Gradient with regularization\n",
    "    gradient = (1 / m) * np.dot(X.T, (h - y))\n",
    "    gradient[1:] += (lambda_val / m) * theta[1:]\n",
    "    \n",
    "    return cost, gradient\n",
    "\n",
    "def train_logistic_regression(X, y, learning_rate, num_iterations, lambda_val=0):\n",
    "    m, n = X.shape\n",
    "    X = np.hstack((np.ones((m, 1)), X.toarray()))  # Add a bias term\n",
    "    \n",
    "    theta = np.zeros(n + 1)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        cost, gradient = compute_cost_and_gradient(X, y, theta, lambda_val)\n",
    "        theta -= learning_rate * gradient\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Iteration {i}, Cost: {cost}')\n",
    "    \n",
    "    return theta\n",
    "\n",
    "def predict(X, theta):\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X.toarray()))\n",
    "    probabilities = sigmoid(np.dot(X, theta))\n",
    "    return (probabilities >= 0.5).astype(int)\n",
    "\n",
    "raw_mail_data = pd.read_csv('mail_data.csv')\n",
    "\n",
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)), '')\n",
    "\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category'] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category'] = 1\n",
    "\n",
    "X = mail_data['Message']\n",
    "Y = mail_data['Category'].astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "\n",
    "feature_extraction = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True)\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_iterations = 5000\n",
    "\n",
    "theta = train_logistic_regression(X_train_features, Y_train, learning_rate, num_iterations)\n",
    "\n",
    "# Evaluate the model\n",
    "prediction_on_training_data = predict(X_train_features, theta)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)\n",
    "print('Accuracy on training data:', accuracy_on_training_data)\n",
    "\n",
    "prediction_on_test_data = predict(X_test_features, theta)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)\n",
    "print('Accuracy on test data:', accuracy_on_test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with l1 regulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Cost: 0.6931471805599451\n",
      "Iteration 1000, Cost: 0.3352126624530808\n",
      "Iteration 2000, Cost: 0.2912077386936038\n",
      "Iteration 3000, Cost: 0.25775100867515055\n",
      "Iteration 4000, Cost: 0.23224409606203558\n",
      "Accuracy on training data with L1 regularization: 0.9113753645950191\n",
      "Accuracy on test data with L1 regularization: 0.9130044843049328\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.2\n",
    "num_iterations = 5000\n",
    "# Function to calculate cost and gradient with L1 regularization\n",
    "def compute_cost_and_gradient_l1(X, y, theta, lambda_val=0):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    regularization_term = (lambda_val / (2 * m)) * np.sum(np.abs(theta[1:]))\n",
    "    \n",
    "    cost = (-1 / m) * (np.dot(y, np.log(h)) + np.dot((1 - y), np.log(1 - h))) + regularization_term\n",
    "    \n",
    "    # Gradient with L1 regularization\n",
    "    gradient = (1 / m) * np.dot(X.T, (h - y))\n",
    "    gradient[1:] += (lambda_val / m) * np.sign(theta[1:])\n",
    "    \n",
    "    return cost, gradient\n",
    "\n",
    "# Function to train logistic regression with L1 regularization using gradient descent\n",
    "def train_logistic_regression_l1(X, y, learning_rate, num_iterations, lambda_val=0):\n",
    "    m, n = X.shape\n",
    "    X = np.hstack((np.ones((m, 1)), X.toarray()))  # Add a bias term\n",
    "    \n",
    "    theta = np.zeros(n + 1)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        cost, gradient = compute_cost_and_gradient_l1(X, y, theta, lambda_val)\n",
    "        theta -= learning_rate * gradient\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Iteration {i}, Cost: {cost}')\n",
    "    \n",
    "    return theta\n",
    "\n",
    "# Train logistic regression model with L1 regularization\n",
    "theta_l1 = train_logistic_regression_l1(X_train_features, Y_train, learning_rate, num_iterations, lambda_val=0.1)\n",
    "\n",
    "# Evaluate the model with L1 regularization\n",
    "prediction_on_training_data_l1 = predict(X_train_features, theta_l1)\n",
    "accuracy_on_training_data_l1 = accuracy_score(Y_train, prediction_on_training_data_l1)\n",
    "print('Accuracy on training data with L1 regularization:', accuracy_on_training_data_l1)\n",
    "\n",
    "prediction_on_test_data_l1 = predict(X_test_features, theta_l1)\n",
    "accuracy_on_test_data_l1 = accuracy_score(Y_test, prediction_on_test_data_l1)\n",
    "print('Accuracy on test data with L1 regularization:', accuracy_on_test_data_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
